$ brew tap homebrew/versions
$ brew install cmake maven openssl protobuf250 snappy

Warning: maven-3.3.9 already installed
Warning: openssl-1.0.2j already installed
==> Downloading https://homebrew.bintray.com/bottles/cmake-3.7.1.yosemite.bottle.tar.gz
######################################################################## 100.0%
==> Pouring cmake-3.7.1.yosemite.bottle.tar.gz
==> Caveats
Emacs Lisp files have been installed to:
  /usr/local/share/emacs/site-lisp/cmake
==> Summary
í ¼í½º  /usr/local/Cellar/cmake/3.7.1: 2,143 files, 29.3M
==> Installing protobuf250 from homebrew/versions
==> Downloading https://homebrew.bintray.com/bottles-versions/protobuf250-2.5.0.yosemite.bottle.tar.gz
######################################################################## 100.0%
==> Pouring protobuf250-2.5.0.yosemite.bottle.tar.gz
==> Caveats
Editor support and examples have been installed to:
  /usr/local/Cellar/protobuf250/2.5.0/share/doc/protobuf250
==> Summary
í ¼í½º  /usr/local/Cellar/protobuf250/2.5.0: 78 files, 5.5M
==> Downloading https://homebrew.bintray.com/bottles/snappy-1.1.3.yosemite.bottle.tar.gz
######################################################################## 100.0%
==> Pouring snappy-1.1.3.yosemite.bottle.tar.gz
í ¼í½º  /usr/local/Cellar/snappy/1.1.3: 20 files, 414K


=================================================



###############################################################################################################################################
###############################################################################################################################################
Installing the right libprotoc version (2.5.0): http://stackoverflow.com/questions/21775151/installing-google-protocol-buffers-on-mac
$ brew tap homebrew/versions
$ brew install protobuf250
If you already have a protocol buffer version that you tried to install from source, you can type the following into a terminal to have the source code overwritten by the homebrew version:
$ brew link --force --overwrite protobuf250
Check that you now have the correct version installed by typing:
$ protoc --version
It should display 2.5.0


Building Hadoop for Mac OS X:
https://gist.github.com/zedar/f631ace0759c1d512573
###############################################################################################################################################
###############################################################################################################################################
sudo lsof -i :8888
vi ~/.bash_profile
######################################
Apache Hadoop: finally that works all the way
######################################
1. brew install hadoop
==> Using the sandbox
==> Downloading https://www.apache.org/dyn/closer.cgi?path=hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
Already downloaded: /Users/eliagbayani/Library/Caches/Homebrew/hadoop-2.7.3.tar.gz
==> Caveats
In Hadoop's config file:
  /usr/local/Cellar/hadoop/2.7.3/libexec/etc/hadoop/hadoop-env.sh,
  /usr/local/Cellar/hadoop/2.7.3/libexec/etc/hadoop/mapred-env.sh and
  /usr/local/Cellar/hadoop/2.7.3/libexec/etc/hadoop/yarn-env.sh
$JAVA_HOME has been set to be the output of:
  /usr/libexec/java_home
==> Summary
í ¼í½º  /usr/local/Cellar/hadoop/2.7.3: 6,328 files, 312.8M, built in 20 seconds

2. in etc/hadoop/hadoop-env.sh
only entry was:
# The java implementation to use.
export JAVA_HOME="$(/usr/libexec/java_home)"

3. $ vi ~/.bash_profile
#set java home
export JAVA_HOME=$(/usr/libexec/java_home)
#set 2 hadoop vars
export HADOOP_INSTALL=/usr/local/Cellar/hadoop/2.7.3/libexec
export HADOOP_OPTS="$HADOOP_OPTS -Djava.library.path=$HADOOP_INSTALL/lib/native/osx"

4. Setting up Hadoop 2.6 on Mac OS X Yosemite
http://zhongyaonan.com/hadoop-tutorial/setting-up-hadoop-2-6-on-mac-osx-yosemite.html


5. Apache Hadoop - add native libraries
https://gist.github.com/zedar/f631ace0759c1d512573


6. Run test:
Based from: http://zhongyaonan.com/hadoop-tutorial/setting-up-hadoop-2-6-on-mac-osx-yosemite.html

***Sometimes datanode fails, if it does just delete tmp files like so:
sudo rm -R /tmp/*
sudo rm -r /tmp
sudo mkdir -p /tmp
sudo chown eliagbayani:hadoop /tmp
->create a hadoop group, if there is none
sudo chmod 750 /tmp

***sometimes namenode becomes safemode for some reason, to fix:
bin/hadoop dfsadmin -safemode leave
hdfs dfsadmin -safemode leave

Also in hdfs-site.xml, add this entry:
<property>
    <name>dfs.safemode.threshold.pct</name>
    <value>0</value>
</property>

***if errors occure, sometimes you just need to close all open ports and restart a new terminal window, and start from step 1.

cd /usr/local/Cellar/hadoop/2.7.3/libexec
bin/hdfs namenode -format
sbin/start-dfs.sh
bin/hdfs dfs -mkdir /user
bin/hdfs dfs -mkdir /user/eliagbayani
sbin/start-yarn.sh
bin/hdfs dfs -put etc/hadoop input
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output 'dfs[a-z.]+'
bin/hdfs dfs -get output output
cat output/*
bin/hdfs dfs -cat output/*
sbin/stop-yarn.sh
sbin/stop-dfs.sh

######################################
Apache Hadoop
######################################
[/usr/local/Cellar/hadoop/2.7.3/libexec]

http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html

to fix: ssh error: "connect to host localhost port 22: Connection refused"
http://stackoverflow.com/questions/17335728/connect-to-host-localhost-port-22-connection-refused

brew install hadoop
In Hadoop's config file:
  /usr/local/Cellar/hadoop/2.7.3/libexec/etc/hadoop/hadoop-env.sh,
  /usr/local/Cellar/hadoop/2.7.3/libexec/etc/hadoop/mapred-env.sh and
  /usr/local/Cellar/hadoop/2.7.3/libexec/etc/hadoop/yarn-env.sh
$JAVA_HOME has been set to be the output of:
  /usr/libexec/java_home
==> Summary
$  /usr/local/Cellar/hadoop/2.7.3:

start following steps now:
cd /usr/local/Cellar/hadoop/2.7.3/libexec

--- Standalone Operation: steps work! --- http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation
$ mkdir input
$ cp etc/hadoop/*.xml input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output 'dfs[a-z.]+'
$ cat output/*

--- Pseudo-Distributed Operation --- http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation
Steps:
1. kill :9000 from listening fpm
e.g. sudo lsof -i :9000

1.
etc/hadoop/core-site.xml: {<value>hdfs://localhost:9000</value> change to: <value>hdfs://0.0.0.0:9000</value>}
etc/hadoop/hdfs-site.xml:

2.
$ bin/hdfs namenode -format
$ sbin/start-dfs.sh

**NameNode - http://localhost:50070/ -> works
**DataNode - http://localhost:50075/ -> works

--- YARN on a Single Node --- http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#YARN_on_a_Single_Node
etc/hadoop/mapred-site.xml:
etc/hadoop/yarn-site.xml:
Start ResourceManager daemon and NodeManager daemon:
$ sbin/start-yarn.sh
ResourceManager - http://localhost:8088/
When done, stop the daemons with:
$ sbin/stop-yarn.sh




